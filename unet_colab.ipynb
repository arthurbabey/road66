{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet-colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurbabey/road66/blob/master/unet_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPCdsZZqymCk",
        "colab_type": "code",
        "outputId": "e68dedcc-5ee8-4956-c9ae-f61a54865aae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "pip install keras-unet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-unet\n",
            "  Downloading https://files.pythonhosted.org/packages/e8/6a/06806e2a778e793e8023316a235ab1fd6c4642cca3a1f81dfa617d48c0f8/keras_unet-0.0.7-py3-none-any.whl\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-unet) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-unet) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-unet) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-unet) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-unet) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-unet) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-unet) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-unet) (1.17.4)\n",
            "Installing collected packages: keras-unet\n",
            "Successfully installed keras-unet-0.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IogOmTmi4QcH",
        "colab_type": "code",
        "outputId": "f799bf2b-9689-4071-eb9a-9ba0ab2c41f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras_unet.models import satellite_unet\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85maIDrJ4dK-",
        "colab_type": "code",
        "outputId": "f471069e-aa88-4188-f4a2-0cc7d38eb54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBURgm_c4lkc",
        "colab_type": "code",
        "outputId": "768f41e3-8a81-40d6-e160-76be02ac3c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "model = satellite_unet(input_shape=(512, 512, 3))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6g2cNdL5H_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os,sys\n",
        "from PIL import Image\n",
        "import sys\n",
        "sys.path.append('/Users/arthurbabey/Documents/master2/ML/road66/scripts')\n",
        "\n",
        "\n",
        "from skimage.transform import rotate\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGFWJndu5hJg",
        "colab_type": "code",
        "outputId": "a7842e49-6530-47fb-c8ae-a77ac5e92d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-q0opgk5jjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(infilename):\n",
        "    data = mpimg.imread(infilename)\n",
        "    return data\n",
        "\n",
        "def img_float_to_uint8(img):\n",
        "    rimg = img - np.min(img)\n",
        "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
        "    return rimg\n",
        "\n",
        "# Concatenate an image and its groundtruth\n",
        "def concatenate_images(img, gt_img):\n",
        "    nChannels = len(gt_img.shape)\n",
        "    w = gt_img.shape[0]\n",
        "    h = gt_img.shape[1]\n",
        "    if nChannels == 3:\n",
        "        cimg = np.concatenate((img, gt_img), axis=1)\n",
        "    else:\n",
        "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
        "        gt_img8 = img_float_to_uint8(gt_img)\n",
        "        gt_img_3c[:,:,0] = gt_img8\n",
        "        gt_img_3c[:,:,1] = gt_img8\n",
        "        gt_img_3c[:,:,2] = gt_img8\n",
        "        img8 = img_float_to_uint8(img)\n",
        "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
        "    return cimg\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Convert array of labels to an image\n",
        "\n",
        "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
        "    im = np.zeros([imgwidth, imgheight])\n",
        "    idx = 0\n",
        "    for i in range(0,imgheight,h):\n",
        "        for j in range(0,imgwidth,w):\n",
        "            im[j:j+w, i:i+h] = labels[idx]\n",
        "            idx = idx + 1\n",
        "    return im\n",
        "\n",
        "def value_to_class(v, foreground_threshold=0.25): #modifier leur fonction en ajoutant f_t en param\n",
        "\n",
        "    df = np.sum(v)\n",
        "    if df > foreground_threshold:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "def rotate_images(X, Y , degrees):\n",
        "    \"\"\"\n",
        "    increase the number of data\n",
        "    by adding rotations of the base data\n",
        "    \"\"\"\n",
        "\n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "    rotimg = np.zeros(X.shape)\n",
        "    rotgtimg = np.zeros(Y.shape)\n",
        "    \n",
        "    Xtemp = X\n",
        "    Ytemp = Y\n",
        "    \n",
        "    #rotate all images by degree and add them to the data vector\n",
        "    for degree in degrees:\n",
        "        for i in range(len(Xtemp)):\n",
        "            rotimg[i] = rotate(Xtemp[i], degree, resize=False, mode='reflect')\n",
        "            rotgtimg[i] = rotate(Ytemp[i], degree, resize=False, mode='reflect')\n",
        "        X = np.concatenate([X,rotimg])\n",
        "        Y = np.concatenate([Y,rotgtimg])\n",
        "\n",
        "    return X,Y\n",
        "\n",
        "def resize_image(X, Y, size = 512):\n",
        "  \n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)\n",
        "    Xlist = []\n",
        "    Ylist = []\n",
        "\n",
        "    Xresize = np.asarray([resize(X[i], (size,size), mode = 'reflect') for i in range(X.shape[0])])\n",
        "    Yresize = np.asarray([resize(Y[i], (size,size), mode = 'reflect') for i in range(X.shape[0])])\n",
        "\n",
        "                        \n",
        "    return Xresize, Yresize\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "def create_submission(y_pred, submission_filename, patch_size = 16, images_size = 608):\n",
        "    n_patches = images_size // patch_size\n",
        "    y_pred = np.reshape(y_pred, (-1, n_patches, n_patches))\n",
        "\n",
        "    with open(submission_filename, 'w') as f:\n",
        "        f.write('id,prediction\\n')\n",
        "        for i in range(y_pred.shape[0]):\n",
        "            img = y_pred[i]\n",
        "            for j in range(img.shape[0]):\n",
        "                for k in range(img.shape[1]):\n",
        "                    name = '{:03d}_{}_{},{}'.format(i + 1, j * patch_size, k * patch_size, int(img[j,k]))\n",
        "                    f.write(name + '\\n')\n",
        "\n",
        "def balance_data(x_train, y_train):\n",
        "    c0 = 0  # bgrd\n",
        "    c1 = 0  # road\n",
        "    for i in range(len(y_train)):\n",
        "        if y_train[i][0] == 1:\n",
        "            c0 = c0 + 1\n",
        "        else:\n",
        "            c1 = c1 + 1\n",
        "    print('Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
        "\n",
        "    print('Balancing training data...')\n",
        "    min_c = min(c0, c1)\n",
        "    idx0 = [i for i, j in enumerate(y_train) if j[0] == 1]\n",
        "    idx1 = [i for i, j in enumerate(y_train) if j[1] == 1]\n",
        "    new_indices = idx0[0:min_c] + idx1[0:min_c]\n",
        "    print(len(new_indices))\n",
        "    print(x_train.shape)\n",
        "    x_train = x_train[new_indices, :, :, :]\n",
        "    y_train = y_train[new_indices]\n",
        "\n",
        "    train_size = y_train.shape[0]\n",
        "\n",
        "    c0 = 0\n",
        "    c1 = 0\n",
        "    for i in range(len(y_train)):\n",
        "        if y_train[i][0] == 1:\n",
        "            c0 = c0 + 1\n",
        "        else:\n",
        "            c1 = c1 + 1\n",
        "    print('Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
        "\n",
        "    return x_train, y_train \n",
        "\n",
        "\n",
        "def img_crop(im, w, h, border = 0, step = 16):\n",
        "    \"\"\"\n",
        "    Return the patches list of an image.\n",
        "    \"\"\"\n",
        "    list_patches = []\n",
        "    imgwidth = im.shape[0]\n",
        "    imgheight = im.shape[1]\n",
        "    is_2d = len(im.shape) < 3\n",
        "    if border != 0:\n",
        "        im_r = np.pad(im[:,:,0], ((border, border), (border, border)), 'reflect')\n",
        "        im_g = np.pad(im[:,:,1], ((border, border), (border, border)), 'reflect')\n",
        "        im_b = np.pad(im[:,:,2], ((border, border), (border, border)), 'reflect')\n",
        "        im = np.dstack((im_r, im_g, im_b))\n",
        "    for i in range(0,imgheight,step):\n",
        "        for j in range(0,imgwidth,step):\n",
        "            if is_2d:\n",
        "                im_patch = im[j:j+w+2*border, i:i+h+2*border]\n",
        "            else:\n",
        "                im_patch = im[j:j+w+2*border, i:i+h+2*border, :]\n",
        "            list_patches.append(im_patch)\n",
        "    return list_patches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnDfgued5y_C",
        "colab_type": "code",
        "outputId": "1c28c0e9-f959-4cb7-96d9-efd0f69da799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Loaded a set of images\n",
        "root_dir = \"drive/My Drive/training/\"\n",
        "\n",
        "image_dir = root_dir + \"images/\"\n",
        "files = os.listdir(image_dir)\n",
        "n = len(files) # Use all images\n",
        "print(\"Loading \" + str(n) + \" testing images\")\n",
        "imgs = [load_image(image_dir + files[i]) for i in range(100)]\n",
        "\n",
        "gt_dir = root_dir + \"groundtruth/\"\n",
        "print(\"Loading \" + str(n) + \" groundtruth\")\n",
        "gt_imgs = [load_image(gt_dir + files[i]) for i in range(100)]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading 100 testing images\n",
            "Loading 100 groundtruth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9779P9O52A1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs, gt_imgs = rotate_images(imgs, gt_imgs, [15, 45, 60])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzWiXAQg54Jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "# Preparation testing data to make a submission\n",
        "# \n",
        "\n",
        "# \n",
        "# Ordering image\n",
        "# \n",
        "root_testdir = \"drive/My Drive/test_set_images\"\n",
        "test_names = os.listdir(root_testdir)\n",
        "\n",
        "\n",
        "num_test = len(test_names)\n",
        "order = [int(test_names[i].split(\"_\")[1]) for i in range(num_test)]\n",
        "index = np.argsort(order)\n",
        "\n",
        "# Load image and reorder them\n",
        "imgs_test = [load_image(os.path.join(root_testdir, test_names[i], test_names[i]) + \".png\") \n",
        "             for i in range(num_test)]\n",
        "imgs_test = [imgs_test[i] for i in index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5k4sd2N68r9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xr, Yr = resize_image(imgs, gt_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWiCAJpA_oCZ",
        "colab_type": "code",
        "outputId": "82b2e767-be3f-49a5-f4bb-e8003037b9a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xr.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 512, 512, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5Z6roEC7GDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(Xr, Yr, \n",
        "                                                      test_size=0.25,  random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fPuFEbmGn6c",
        "colab_type": "code",
        "outputId": "67b5ce95-9121-4e76-96e4-d42b1671f04f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((75, 512, 512, 3), (75, 512, 512))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPC0raZGFK56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIo7_5EKXoBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_unet.models import custom_unet\n",
        "\n",
        "input_shape = x_train[0].shape\n",
        "\n",
        "model = custom_unet(\n",
        "    input_shape,\n",
        "    use_batch_norm=False,\n",
        "    num_classes=2,\n",
        "    filters=64,\n",
        "    dropout=0.2,\n",
        "    output_activation='sigmoid'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu1k-Iy97GVS",
        "colab_type": "code",
        "outputId": "1a8aa559-9941-425b-c909-14e089837d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', #compile the model\n",
        "              optimizer='adam',\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train,              #fitting the model \n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              #validation_data=(x_val, y_val),\n",
        "              #callbacks = [tensorboard_callback]\n",
        "         )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-5a8e3b3fe763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m model.fit(x_train, y_train,              #fitting the model \n\u001b[1;32m      7\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m               \u001b[0;31m#validation_data=(x_val, y_val),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m               \u001b[0;31m#callbacks = [tensorboard_callback]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected conv2d_85 to have 4 dimensions, but got array with shape (75, 512, 512)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y79AfsL17Gn0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f0268ec-4a25-48d9-a866-12e2b7381b22"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 512, 512, 64) 1792        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 512, 512, 64) 0           conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 512, 512, 64) 36928       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 256, 256, 64) 0           conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 256, 256, 128 73856       max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 256, 256, 128 0           conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 256, 256, 128 147584      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 128, 128, 128 0           conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 128, 128, 256 295168      max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 128, 128, 256 0           conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 128, 128, 256 590080      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 64, 64, 256)  0           conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 64, 64, 512)  1180160     max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 64, 64, 512)  0           conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 64, 64, 512)  2359808     dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 32, 32, 512)  0           conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 32, 32, 1024) 4719616     max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 1024) 0           conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 32, 32, 1024) 9438208     dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_14 (Conv2DTran (None, 64, 64, 512)  2097664     conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 64, 64, 1024) 0           conv2d_transpose_14[0][0]        \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 64, 64, 512)  2359808     conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_15 (Conv2DTran (None, 128, 128, 256 524544      conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 128, 128, 512 0           conv2d_transpose_15[0][0]        \n",
            "                                                                 conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 128, 128, 256 590080      conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_16 (Conv2DTran (None, 256, 256, 128 131200      conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 256, 256, 256 0           conv2d_transpose_16[0][0]        \n",
            "                                                                 conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 256, 256, 128 295040      concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 256, 256, 128 147584      conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_17 (Conv2DTran (None, 512, 512, 64) 32832       conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 512, 512, 128 0           conv2d_transpose_17[0][0]        \n",
            "                                                                 conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 512, 512, 64) 36928       conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 512, 512, 2)  130         conv2d_84[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 31,031,810\n",
            "Trainable params: 31,031,810\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7vY9x7KW3pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}