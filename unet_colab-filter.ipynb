{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet-colab.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthurbabey/road66/blob/arthur/unet_colab-filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPCdsZZqymCk",
        "colab_type": "code",
        "outputId": "bf8c8706-b7cf-4560-d1a3-e4655ee75305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os,sys\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "sys.path.append('/Users/arthurbabey/Documents/master2/ML/road66/scripts')\n",
        "\n",
        "\n",
        "from skimage.transform import rotate\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "def load_image(infilename):\n",
        "    data = mpimg.imread(infilename)\n",
        "    return data\n",
        "\n",
        "\n",
        "# Concatenate an image and its groundtruth\n",
        "def concatenate_images(img, gt_img):\n",
        "    nChannels = len(gt_img.shape)\n",
        "    w = gt_img.shape[0]\n",
        "    h = gt_img.shape[1]\n",
        "    if nChannels == 3:\n",
        "        cimg = np.concatenate((img, gt_img), axis=1)\n",
        "    else:\n",
        "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
        "        gt_img8 = img_float_to_uint8(gt_img)\n",
        "        gt_img_3c[:,:,0] = gt_img8\n",
        "        gt_img_3c[:,:,1] = gt_img8\n",
        "        gt_img_3c[:,:,2] = gt_img8\n",
        "        img8 = img_float_to_uint8(img)\n",
        "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
        "    return cimg\n",
        "\n",
        "# Convert array of labels to an image\n",
        "\n",
        "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
        "    im = np.zeros([imgwidth, imgheight])\n",
        "    idx = 0\n",
        "    for i in range(0,imgheight,h):\n",
        "        for j in range(0,imgwidth,w):\n",
        "            im[j:j+w, i:i+h] = labels[idx]\n",
        "            idx = idx + 1\n",
        "    return im\n",
        "\n",
        "def value_to_class(v, foreground_threshold=0.25):\n",
        "\n",
        "    df = np.sum(v)\n",
        "    if df > foreground_threshold:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "def rotate_images(X, Y , degrees):\n",
        "    \"\"\"\n",
        "    increase the number of data\n",
        "    by adding rotations of the base data\n",
        "    \"\"\"\n",
        "\n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "    rotimg = np.zeros(X.shape)\n",
        "    rotgtimg = np.zeros(Y.shape)\n",
        "\n",
        "    Xtemp = X\n",
        "    Ytemp = Y\n",
        "\n",
        "    #rotate all images by degree and add them to the data vector\n",
        "    for degree in degrees:\n",
        "        for i in range(len(Xtemp)):\n",
        "            rotimg[i] = rotate(Xtemp[i], degree, resize=False, mode='reflect')\n",
        "            rotgtimg[i] = rotate(Ytemp[i], degree, resize=False, mode='reflect')\n",
        "        X = np.concatenate([X,rotimg])\n",
        "        Y = np.concatenate([Y,rotgtimg])\n",
        "\n",
        "    return X,Y\n",
        "\n",
        "def resize_image(X, Y, size = 512):\n",
        "\n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)\n",
        "\n",
        "    Xresize = np.asarray([resize(X[i], (size,size), mode = 'reflect') for i in range(X.shape[0])])\n",
        "    Yresize = np.asarray([resize(Y[i], (size,size), mode = 'reflect') for i in range(X.shape[0])])\n",
        "\n",
        "\n",
        "    return Xresize, Yresize\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_submission(y_pred, submission_filename, patch_size = 16, images_size = 608):\n",
        "    n_patches = images_size // patch_size\n",
        "    y_pred = np.reshape(y_pred, (-1, n_patches, n_patches))\n",
        "\n",
        "    with open(submission_filename, 'w') as f:\n",
        "        f.write('id,prediction\\n')\n",
        "        for i in range(y_pred.shape[0]):\n",
        "            img = y_pred[i]\n",
        "            for j in range(img.shape[0]):\n",
        "                for k in range(img.shape[1]):\n",
        "                    name = '{:03d}_{}_{},{}'.format(i + 1, j * patch_size, k * patch_size, int(img[j,k]))\n",
        "                    f.write(name + '\\n')\n",
        "\n",
        "\n",
        "def balance_data(x_train, y_train):\n",
        "    c0 = 0  # bgrd\n",
        "    c1 = 0  # road\n",
        "    for i in range(len(y_train)):\n",
        "        if y_train[i][0] == 1:\n",
        "            c0 = c0 + 1\n",
        "        else:\n",
        "            c1 = c1 + 1\n",
        "    print('Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
        "\n",
        "    print('Balancing training data...')\n",
        "    min_c = min(c0, c1)\n",
        "    idx0 = [i for i, j in enumerate(y_train) if j[0] == 1]\n",
        "    idx1 = [i for i, j in enumerate(y_train) if j[1] == 1]\n",
        "    new_indices = idx0[0:min_c] + idx1[0:min_c]\n",
        "    print(len(new_indices))\n",
        "    print(x_train.shape)\n",
        "    x_train = x_train[new_indices, :, :, :]\n",
        "    y_train = y_train[new_indices]\n",
        "\n",
        "    train_size = y_train.shape[0]\n",
        "\n",
        "    c0 = 0\n",
        "    c1 = 0\n",
        "    for i in range(len(y_train)):\n",
        "        if y_train[i][0] == 1:\n",
        "            c0 = c0 + 1\n",
        "        else:\n",
        "            c1 = c1 + 1\n",
        "    print('Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
        "\n",
        "    return x_train, y_train\n",
        "\n",
        "\n",
        "def img_crop(im, w, h, border = 0, step = 16):\n",
        "    \"\"\"\n",
        "    Return the patches list of an image.\n",
        "    \"\"\"\n",
        "    list_patches = []\n",
        "    imgwidth = im.shape[0]\n",
        "    imgheight = im.shape[1]\n",
        "    is_2d = len(im.shape) < 3\n",
        "    if border != 0:\n",
        "        im_r = np.pad(im[:,:,0], ((border, border), (border, border)), 'reflect')\n",
        "        im_g = np.pad(im[:,:,1], ((border, border), (border, border)), 'reflect')\n",
        "        im_b = np.pad(im[:,:,2], ((border, border), (border, border)), 'reflect')\n",
        "        im = np.dstack((im_r, im_g, im_b))\n",
        "    for i in range(0,imgheight,step):\n",
        "        for j in range(0,imgwidth,step):\n",
        "            if is_2d:\n",
        "                im_patch = im[j:j+w+2*border, i:i+h+2*border]\n",
        "            else:\n",
        "                im_patch = im[j:j+w+2*border, i:i+h+2*border, :]\n",
        "            list_patches.append(im_patch)\n",
        "    return list_patches\n",
        "\n",
        "\n",
        "def load_trainset(path = 'Data/test_set_images'):\n",
        "\n",
        "    # Loaded a set of images\n",
        "    root_dir = path\n",
        "\n",
        "    image_dir = root_dir + \"images/\"\n",
        "    files = os.listdir(image_dir)\n",
        "    n = len(files) # Use all images\n",
        "    print(\"Loading \" + str(n) + \" testing images\")\n",
        "    imgs = [load_image(image_dir + files[i]) for i in range(100)]\n",
        "\n",
        "    gt_dir = root_dir + \"groundtruth/\"\n",
        "    print(\"Loading \" + str(n) + \" groundtruth\")\n",
        "    gt_imgs = [load_image(gt_dir + files[i]) for i in range(100)]\n",
        "\n",
        "    return imgs, gt_imgs\n",
        "\n",
        "\n",
        "def load_testset(path = 'Data/test_set_images'):\n",
        "\n",
        "\n",
        "  root_testdir = path\n",
        "  test_names = os.listdir(root_testdir)\n",
        "\n",
        "  num_test = len(test_names)\n",
        "  order = [int(test_names[i].split(\"_\")[1]) for i in range(num_test)]\n",
        "  index = np.argsort(order)\n",
        "\n",
        "  # Load image and reorder them\n",
        "  imgs_test = [load_image(os.path.join(root_testdir, test_names[i], test_names[i]) + \".png\")\n",
        "               for i in range(num_test)]\n",
        "  imgs_test = [imgs_test[i] for i in index]\n",
        "\n",
        "  return imgs_test\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85maIDrJ4dK-",
        "colab_type": "code",
        "outputId": "33801eb6-0966-44db-c448-e6222adab8b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6g2cNdL5H_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os,sys\n",
        "from PIL import Image\n",
        "import sys\n",
        "sys.path.append('/Users/arthurbabey/Documents/master2/ML/road66/scripts')\n",
        "\n",
        "\n",
        "from skimage.transform import rotate\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGFWJndu5hJg",
        "colab_type": "code",
        "outputId": "abc1a419-4668-4e5d-d677-0747a11b2cb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLYq2o0QJy3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 2019\n",
        "np.random.seed(seed)\n",
        "tf.set_random_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnDfgued5y_C",
        "colab_type": "code",
        "outputId": "65c5613f-f0e4-46d9-fb38-f577a1d50e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "imgs, gt_imgs = load_trainset(path = 'drive/My Drive/training/')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading 100 testing images\n",
            "Loading 100 groundtruth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzwcZ5WodFvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "# Preparation testing data to make a submission\n",
        "# \n",
        "\n",
        "# \n",
        "# Ordering image\n",
        "# \n",
        "root_testdir = \"drive/My Drive/test_set_images\"\n",
        "test_names = os.listdir(root_testdir)\n",
        "\n",
        "\n",
        "num_test = len(test_names)\n",
        "order = [int(test_names[i].split(\"_\")[1]) for i in range(num_test)]\n",
        "index = np.argsort(order)\n",
        "\n",
        "# Load image and reorder them\n",
        "imgs_test = [load_image(os.path.join(root_testdir, test_names[i], test_names[i]) + \".png\") \n",
        "             for i in range(num_test)]\n",
        "imgs_test = [imgs_test[i] for i in index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9779P9O52A1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs, gt_imgs = rotate_images(imgs, gt_imgs, [ 45])\n",
        "\n",
        "n = len(imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5k4sd2N68r9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size = 400\n",
        "\n",
        "Xr, Yr = resize_image(imgs, gt_imgs, img_size)\n",
        "Yr = np.reshape(Yr, (n, img_size, img_size, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5Z6roEC7GDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 2019\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(Xr, Yr, test_size=0.25,  random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNwDGBB5BjUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "\n",
        "\n",
        "def unet2(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 5, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = Model(input = inputs, output = conv10)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIT775u2Yxpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "\n",
        "\n",
        "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.25)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(2048, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(2048, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(1024, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = Model(input = inputs, output = conv10)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ua8eMgndzfM",
        "colab_type": "code",
        "outputId": "51f52a62-4cf7-4068-b46d-b7060dbad259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "input_size = (img_size, img_size, 3)\n",
        "\n",
        "model = unet(pretrained_weights = None, input_size = input_size)\n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG-5u8X8CjBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Create image generator\n",
        "data_gen_args = dict(rotation_range=5.,\n",
        "        width_shift_range=0,\n",
        "        height_shift_range=0,\n",
        "        shear_range=0,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,)\n",
        "\n",
        "\n",
        "image_datagen = ImageDataGenerator(**data_gen_args, fill_mode ='reflect')\n",
        "\n",
        "seed = 1\n",
        "\n",
        "def XYaugmentGenerator(X1, y, gen, seed = 1, batch_size = 1):\n",
        "    genX1 = gen.flow(X1, y, batch_size=batch_size, seed=seed)\n",
        "    genX2 = gen.flow(y, X1, batch_size=batch_size, seed=seed)\n",
        "    while True:\n",
        "        X1i = genX1.next()\n",
        "        X2i = genX2.next()\n",
        "\n",
        "        yield X1i[0], X2i[0]\n",
        "\n",
        "train_gen = XYaugmentGenerator(x_train, y_train, image_datagen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fPuFEbmGn6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "\n",
        "model_filename = 'bigplusplus.h5'\n",
        "\n",
        "callback_checkpoint = ModelCheckpoint(model_filename, verbose=1, monitor='val_loss', save_best_only=False)\n",
        "lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1, mode='min', min_lr= 1e-8)\n",
        "es = EarlyStopping(monitor = 'val_loss', patience = 12, mode = 'min')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtUtxfGmCkna",
        "colab_type": "code",
        "outputId": "555c5752-cb92-4553-e6d7-dac6db09289a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer= Adam(lr = 1e-6),\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_gen,\n",
        "    steps_per_epoch=900,\n",
        "    epochs=35,   \n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[callback_checkpoint]\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "900/900 [==============================] - 372s 414ms/step - loss: 0.0766 - binary_accuracy: 0.7368 - val_loss: 0.0784 - val_binary_accuracy: 0.7335\n",
            "\n",
            "Epoch 00001: saving model to bigplusplus.h5\n",
            "Epoch 2/35\n",
            "900/900 [==============================] - 367s 407ms/step - loss: 0.0762 - binary_accuracy: 0.7377 - val_loss: 0.0784 - val_binary_accuracy: 0.7335\n",
            "\n",
            "Epoch 00002: saving model to bigplusplus.h5\n",
            "Epoch 3/35\n",
            " 65/900 [=>............................] - ETA: 5:31 - loss: 0.0786 - binary_accuracy: 0.7311"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-9ea519effec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNJb-ZotEl8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(filepath='drive/My Drive/bigguy.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv1OEx0ycjSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "9f4fd04f-fb22-4002-ec2e-bd60add7a639"
      },
      "source": [
        "model.load_weights('drive/My Drive/bigmodelplus9.h5')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdgNq3HKD3vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_unet.utils import plot_imgs\n",
        "\n",
        "y_pred = model.predict(x_val, batch_size = 1, verbose = 1)\n",
        "y_pred[y_pred < 0.5] = 0\n",
        "y_pred[y_pred >= 0.5] = 1\n",
        "\n",
        "plot_imgs(org_imgs=x_val, mask_imgs=y_val, pred_imgs=y_pred, nm_img_to_plot=24)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl6crbR9jHwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "get_f1(y_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa6h1rBMe6Hp",
        "colab_type": "code",
        "outputId": "394f5dbb-f7cb-4d00-e0d3-072784169dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "test_image_unet_submissionn(imgs_test, size = 400, model = model, filename = 'postppproc.csv')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 127ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqHyH8K9113J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_image_unet_submissionn(imgs_test, size = 400, model = model, filename = 'submission.csv'):\n",
        "\n",
        "\n",
        "  img1 = []\n",
        "  img2 = []\n",
        "  img3 = []\n",
        "  img4 = []\n",
        "\n",
        "  shift = 608 - size\n",
        "\n",
        "\n",
        "  for img in imgs_test:\n",
        "    img = img[0:size, 0:size, :]\n",
        "    img1.append(img)\n",
        "\n",
        "  for img in imgs_test:\n",
        "    img = img[shift:608, 0:size, :]\n",
        "    img2.append(img)\n",
        "\n",
        "  for img in imgs_test:\n",
        "    img = img[0:size, shift:608, :]\n",
        "    img3.append(img)\n",
        "\n",
        "  for img in imgs_test:\n",
        "    img = img[shift:608, shift:608, :]\n",
        "    img4.append(img)\n",
        "\n",
        "\n",
        "  img_pred1 = model.predict(np.asarray(img1), batch_size = 1, verbose = 1)\n",
        "  img_pred2 = model.predict(np.asarray(img2), batch_size = 1, verbose = 1)\n",
        "  img_pred3 = model.predict(np.asarray(img3), batch_size = 1, verbose = 1)\n",
        "  img_pred4 = model.predict(np.asarray(img4), batch_size = 1, verbose = 1)\n",
        "\n",
        "\n",
        "  img_pred1[img_pred1 <= 0.557] = 0\n",
        "  img_pred1[img_pred1 > 0.557] = 1\n",
        "\n",
        "  img_pred2[img_pred2 <= 0.557] = 0\n",
        "  img_pred2[img_pred2 > 0.557] = 1\n",
        "\n",
        "  img_pred3[img_pred3 <= 0.557] = 0\n",
        "  img_pred3[img_pred3 > 0.557] = 1\n",
        "\n",
        "  img_pred4[img_pred4 <= 0.557] = 0\n",
        "  img_pred4[img_pred4 > 0.557] = 1\n",
        "\n",
        "  img1 = np.asarray(img1)\n",
        "  img2 = np.asarray(img2)\n",
        "  img3 = np.asarray(img3)\n",
        "  img4 = np.asarray(img4)\n",
        "\n",
        "  list_m1 = []\n",
        "  list_m2 = []\n",
        "  list_merge = []\n",
        "\n",
        "  for i in range(50):\n",
        "    m1 = np.concatenate((img_pred1[i, 0:shift, :, :], img_pred2[i, :, :, :]), axis = 0)\n",
        "    list_m1.append(m1)\n",
        "    m2 = np.concatenate((img_pred3[i, 0:shift, :, :], img_pred4[i, :, :, :]), axis = 0)\n",
        "    list_m2.append(m2)\n",
        "    \n",
        "  list_m1 = np.asarray(list_m1)\n",
        "  list_m2 = np.asarray(list_m2)\n",
        "\n",
        "  for i in range(50):\n",
        "    merge = np.concatenate((list_m1[i,:,:,:], list_m2[i, :, (size - shift):size, :]), axis=1)\n",
        "    list_merge.append(merge)\n",
        "\n",
        "    \n",
        "  y_pred = np.asarray(list_merge)\n",
        "\n",
        "  pred_patch = [img_crop(y_pred[i], 16, 16) for i in range(y_pred.shape[0])]\n",
        "  pred_patch = np.asarray([pred_patch[i][j] for i in range(len(pred_patch)) for j in range(len(pred_patch[i]))])\n",
        "  pred_patch = np.asarray([value_to_class(np.mean(pred_patch[i]), foreground_threshold=0.229) for i in range(pred_patch.shape[0])])\n",
        "\n",
        "  create_submission(pred_patch, filename)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuB6ZwG5dUEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82157fed-869f-4a90-9118-3cf988654cac"
      },
      "source": [
        "\n",
        "best_score = 0\n",
        "scores = []\n",
        "\n",
        "for t in np.linspace(0.40, 0.60, num = 20):\n",
        "  for f in np.linspace(0.12, 0.38, num = 20):\n",
        "\n",
        "    y_pred = model.predict(x_val, batch_size = 1, verbose = 1)\n",
        "\n",
        "    y_pred[y_pred <= t] = 0\n",
        "    y_pred[y_pred > t] = 1\n",
        "\n",
        "    pred_patch = [img_crop(y_pred[i], 16, 16) for i in range(y_pred.shape[0])]\n",
        "    pred_patch = np.asarray([pred_patch[i][j] for i in range(len(pred_patch)) for j in range(len(pred_patch[i]))])\n",
        "    pred_patch = np.asarray([value_to_class(np.mean(pred_patch[i]), foreground_threshold = f) for i in range(pred_patch.shape[0])])\n",
        "\n",
        "    val_patch = [img_crop(y_val[i], 16, 16) for i in range(y_val.shape[0])]\n",
        "    val_patch = np.asarray([val_patch[i][j] for i in range(len(val_patch)) for j in range(len(val_patch[i]))])\n",
        "    val_patch = np.asarray([value_to_class(np.mean(val_patch[i]), foreground_threshold = f) for i in range(val_patch.shape[0])])\n",
        "\n",
        "\n",
        "    score = f1_score(val_patch, pred_patch)\n",
        "    scores.append(score)\n",
        "\n",
        "    #print(score)\n",
        "    #print( str(t) + '   nnnnn    ' + str(f))\n",
        "\n",
        "    if( score > best_score):\n",
        "      print('Score improve with : foregroud threshold = ' + str(f) + ' threshold = ' + str(t))\n",
        "      best_score = score\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 6s 129ms/step\n",
            "Score improve with : foregroud threshold = 0.12 threshold = 0.4\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "Score improve with : foregroud threshold = 0.16105263157894736 threshold = 0.4\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 7s 131ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "Score improve with : foregroud threshold = 0.12 threshold = 0.4105263157894737\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "Score improve with : foregroud threshold = 0.12 threshold = 0.4210526315789474\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 131ms/step\n",
            "50/50 [==============================] - 7s 131ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "Score improve with : foregroud threshold = 0.12 threshold = 0.43157894736842106\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "Score improve with : foregroud threshold = 0.21578947368421053 threshold = 0.43157894736842106\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 131ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "Score improve with : foregroud threshold = 0.12 threshold = 0.4421052631578948\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "Score improve with : foregroud threshold = 0.2431578947368421 threshold = 0.4736842105263158\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "Score improve with : foregroud threshold = 0.16105263157894736 threshold = 0.4842105263157895\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "Score improve with : foregroud threshold = 0.21578947368421053 threshold = 0.4842105263157895\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "Score improve with : foregroud threshold = 0.16105263157894736 threshold = 0.49473684210526314\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "Score improve with : foregroud threshold = 0.22947368421052633 threshold = 0.49473684210526314\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 6s 130ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 7s 130ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "Score improve with : foregroud threshold = 0.22947368421052633 threshold = 0.5578947368421052\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 128ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n",
            "50/50 [==============================] - 6s 129ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGETa2UyawoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "a8647c2f-9ed1-422f-fa35-dfefa50c72bf"
      },
      "source": [
        "np.linspace(0.12, 0.38, num = 20)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-6138aae7576e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# only call close('all') if any to close\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# close triggers gc.collect, which can be slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGEFDYHmTliG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dfff8f7-281a-4c49-c0a3-27df1362decb"
      },
      "source": [
        "y_val.shape, x_val.shape, np.asarray(imgs_test).shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((80, 400, 400, 1), (80, 400, 400, 3), (50, 608, 608, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3B-s70NTmyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def patches_prediction(img, model, threshold, foreground, size = 400):\n",
        "\n",
        "\n",
        "  img_pred = model.predict(np.asarray(img), batch_size = 1, verbose = 1)\n",
        "  img_pred[img_pred <= threshold] = 0\n",
        "  img_pred[img_pred > threshold] = 1\n",
        "\n",
        "  y_pred = np.asarray(img_pred)\n",
        "\n",
        "  pred_patch = [img_crop(y_pred[i], 16, 16) for i in range(y_pred.shape[0])]\n",
        "  pred_patch = np.asarray([pred_patch[i][j] for i in range(len(pred_patch)) for j in range(len(pred_patch[i]))])\n",
        "  pred_patch = np.asarray([value_to_class(np.mean(pred_patch[i]), foreground) for i in range(pred_patch.shape[0])])\n",
        "\n",
        "  return pred_patch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9jDA4sgUema",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amn8hipvbnS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}